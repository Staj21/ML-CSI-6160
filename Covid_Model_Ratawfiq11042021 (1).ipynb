{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "U5st3AlfhGn2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import scipy.sparse\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import tensorflow_datasets as tfds\n",
    "import IPython\n",
    "import IPython.display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run InitialDataCleanup_Ratawfiq11042021.ipynb\n",
    "IPython.display.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "0xRVuCOTgYi0",
    "outputId": "af39ba7b-3f12-4636-d310-00fd621f2ac5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initclaims_count_regular</th>\n",
       "      <th>contclaims_count_regular</th>\n",
       "      <th>initclaims_count_combined</th>\n",
       "      <th>contclaims_count_combined</th>\n",
       "      <th>bg_posts_ss60</th>\n",
       "      <th>bg_posts_ss70</th>\n",
       "      <th>case_count</th>\n",
       "      <th>death_count</th>\n",
       "      <th>revenue_ss60</th>\n",
       "      <th>revenue_ss70</th>\n",
       "      <th>spend_acf</th>\n",
       "      <th>spend_hcs</th>\n",
       "      <th>gps_retail_and_recreation</th>\n",
       "      <th>gps_grocery_and_pharmacy</th>\n",
       "      <th>gps_transit_stations</th>\n",
       "      <th>gps_workplaces</th>\n",
       "      <th>gps_away_from_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-03-02</th>\n",
       "      <td>11452.428571</td>\n",
       "      <td>169619.714286</td>\n",
       "      <td>15360.0</td>\n",
       "      <td>301818.285714</td>\n",
       "      <td>-0.093543</td>\n",
       "      <td>-0.121143</td>\n",
       "      <td>613391.0</td>\n",
       "      <td>16067.0</td>\n",
       "      <td>-0.400</td>\n",
       "      <td>-0.599</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>-0.0876</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>-0.0943</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.0952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-03</th>\n",
       "      <td>11437.571429</td>\n",
       "      <td>166754.285714</td>\n",
       "      <td>15299.0</td>\n",
       "      <td>226363.714286</td>\n",
       "      <td>-0.103029</td>\n",
       "      <td>-0.126429</td>\n",
       "      <td>614731.0</td>\n",
       "      <td>16090.0</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-0.605</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>-0.0794</td>\n",
       "      <td>-0.163</td>\n",
       "      <td>-0.0857</td>\n",
       "      <td>-0.264</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-04</th>\n",
       "      <td>11422.714286</td>\n",
       "      <td>163888.857143</td>\n",
       "      <td>15238.0</td>\n",
       "      <td>150909.142857</td>\n",
       "      <td>-0.112514</td>\n",
       "      <td>-0.131714</td>\n",
       "      <td>616099.0</td>\n",
       "      <td>16112.0</td>\n",
       "      <td>-0.410</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.0647</td>\n",
       "      <td>-0.159</td>\n",
       "      <td>-0.0843</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-05</th>\n",
       "      <td>11407.857143</td>\n",
       "      <td>161023.428571</td>\n",
       "      <td>15177.0</td>\n",
       "      <td>75454.571429</td>\n",
       "      <td>-0.122000</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>617541.0</td>\n",
       "      <td>16135.0</td>\n",
       "      <td>-0.359</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>-0.130</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-0.0829</td>\n",
       "      <td>-0.261</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>-0.0936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-03-06</th>\n",
       "      <td>11393.000000</td>\n",
       "      <td>158158.000000</td>\n",
       "      <td>15116.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.122000</td>\n",
       "      <td>-0.137000</td>\n",
       "      <td>619020.0</td>\n",
       "      <td>16156.0</td>\n",
       "      <td>-0.367</td>\n",
       "      <td>-0.613</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>-0.0814</td>\n",
       "      <td>-0.260</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>-0.0936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            initclaims_count_regular  ...  gps_away_from_home\n",
       "2021-03-02              11452.428571  ...             -0.0952\n",
       "2021-03-03              11437.571429  ...             -0.0936\n",
       "2021-03-04              11422.714286  ...             -0.0936\n",
       "2021-03-05              11407.857143  ...             -0.0936\n",
       "2021-03-06              11393.000000  ...             -0.0936\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = result\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qPrT3BJotdO"
   },
   "source": [
    "## The newly added columns - to give us ideas of how and when covid-19 cases are reducing and economy is picking up are;\n",
    "\n",
    "**1.) gps_retail_and_recreation\t\n",
    "2.) gps_grocery_and_pharmacy\t\n",
    "3.) gps_transit_stations\t\n",
    "4.) gps_workplaces and\n",
    "5.) gps_away_from_home**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_GnEP87rgYi2"
   },
   "outputs": [],
   "source": [
    "#target_names = ['contclaims_count_regular']\n",
    "target_names = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rxUKPT18gYi3"
   },
   "outputs": [],
   "source": [
    "split_fraction = 0.7\n",
    "train_split = int(split_fraction * int(df.shape[0]))\n",
    "step = 1\n",
    "\n",
    "past = 20\n",
    "future = 1\n",
    "learning_rate = 0.001\n",
    "batch_size = 12\n",
    "\n",
    "sequence_length = int(past / step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "sIlOZvowgYi4",
    "outputId": "dfc7a9bb-347d-4edc-d864-3d972c732cde"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initclaims_count_regular</th>\n",
       "      <th>contclaims_count_regular</th>\n",
       "      <th>initclaims_count_combined</th>\n",
       "      <th>contclaims_count_combined</th>\n",
       "      <th>bg_posts_ss60</th>\n",
       "      <th>bg_posts_ss70</th>\n",
       "      <th>case_count</th>\n",
       "      <th>death_count</th>\n",
       "      <th>revenue_ss60</th>\n",
       "      <th>revenue_ss70</th>\n",
       "      <th>spend_acf</th>\n",
       "      <th>spend_hcs</th>\n",
       "      <th>gps_retail_and_recreation</th>\n",
       "      <th>gps_grocery_and_pharmacy</th>\n",
       "      <th>gps_transit_stations</th>\n",
       "      <th>gps_workplaces</th>\n",
       "      <th>gps_away_from_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-03-07</th>\n",
       "      <td>5150.000000</td>\n",
       "      <td>77661.0</td>\n",
       "      <td>5150.000000</td>\n",
       "      <td>77661.0</td>\n",
       "      <td>0.072643</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>-0.0413</td>\n",
       "      <td>-0.03040</td>\n",
       "      <td>-0.02080</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-08</th>\n",
       "      <td>5176.857143</td>\n",
       "      <td>77389.0</td>\n",
       "      <td>5176.857143</td>\n",
       "      <td>77389.0</td>\n",
       "      <td>0.063086</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>-0.0357</td>\n",
       "      <td>-0.02830</td>\n",
       "      <td>0.00586</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-09</th>\n",
       "      <td>5203.714286</td>\n",
       "      <td>77117.0</td>\n",
       "      <td>5203.714286</td>\n",
       "      <td>77117.0</td>\n",
       "      <td>0.053529</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>-0.0370</td>\n",
       "      <td>-0.02430</td>\n",
       "      <td>-0.04010</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>0.0139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-10</th>\n",
       "      <td>5230.571429</td>\n",
       "      <td>76845.0</td>\n",
       "      <td>5230.571429</td>\n",
       "      <td>76845.0</td>\n",
       "      <td>0.043971</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>-0.0430</td>\n",
       "      <td>-0.00913</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-11</th>\n",
       "      <td>5257.428571</td>\n",
       "      <td>76573.0</td>\n",
       "      <td>5257.428571</td>\n",
       "      <td>76573.0</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>-0.0489</td>\n",
       "      <td>-0.01250</td>\n",
       "      <td>0.15600</td>\n",
       "      <td>0.0957</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0800</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.0109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            initclaims_count_regular  ...  gps_away_from_home\n",
       "2020-03-07               5150.000000  ...              0.0156\n",
       "2020-03-08               5176.857143  ...              0.0156\n",
       "2020-03-09               5203.714286  ...              0.0139\n",
       "2020-03-10               5230.571429  ...              0.0125\n",
       "2020-03-11               5257.428571  ...              0.0109\n",
       "\n",
       "[5 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = list(df.columns)\n",
    "features = df[titles]\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hVi3lVV4gYi5",
    "outputId": "4ac87200-c90a-4682-cfaf-29141caeed8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(344, 344, 365)"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = past + future\n",
    "end = start + train_split\n",
    "\n",
    "x_data = features.values[0: -start]\n",
    "y_data = features[target_names].values[start:]\n",
    "\n",
    "x_train = x_data[:train_split]\n",
    "x_val = x_data[train_split:]\n",
    "\n",
    "y_train = y_data[:train_split]\n",
    "y_val = y_data[train_split:]\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "x_train_scaled = x_scaler.fit_transform(x_train)\n",
    "x_val_scaled = x_scaler.transform(x_val)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y_train_scaled = y_scaler.fit_transform(y_train)\n",
    "y_val_scaled = y_scaler.transform(y_val)\n",
    "\n",
    "len(x_train) + len(x_val), len(y_train) + len(y_val), len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "xQ2OngcugYi6"
   },
   "outputs": [],
   "source": [
    "dataset_train = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_train_scaled,\n",
    "    y_train_scaled,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9z1-c3C6gYi7"
   },
   "outputs": [],
   "source": [
    "dataset_val = keras.preprocessing.timeseries_dataset_from_array(\n",
    "    x_val_scaled,\n",
    "    y_val_scaled,\n",
    "    sequence_length=sequence_length,\n",
    "    sampling_rate=step,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S67GkKXlgYi7",
    "outputId": "98aa3b13-579b-402b-c0ac-e02713e71f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (12, 20, 17)\n",
      "Target shape: (12, 17)\n",
      "dataset val\n",
      "x shape: (12, 20, 17)\n",
      "y shape: (12, 17)\n",
      "x shape: (12, 20, 17)\n",
      "y shape: (12, 17)\n",
      "x shape: (12, 20, 17)\n",
      "y shape: (12, 17)\n",
      "x shape: (12, 20, 17)\n",
      "y shape: (12, 17)\n",
      "x shape: (12, 20, 17)\n",
      "y shape: (12, 17)\n",
      "x shape: (10, 20, 17)\n",
      "y shape: (10, 17)\n",
      "length of x_val: 89\n",
      "length of validation data: 6\n",
      "number of batches: 6\n"
     ]
    }
   ],
   "source": [
    "for batch in dataset_train.take(1):\n",
    "    inputs, targets = batch\n",
    "print(\"Input shape:\", inputs.numpy().shape)\n",
    "print(\"Target shape:\", targets.numpy().shape)\n",
    "\n",
    "print('dataset val')\n",
    "i = 0\n",
    "for j in dataset_val:\n",
    "    x, y = j\n",
    "    print('x shape:', x.shape)\n",
    "    print('y shape:', y.shape)\n",
    "    i = i + 1\n",
    "\n",
    "print(f'length of x_val: {len(x_val)}')\n",
    "print(f'length of validation data: {len(dataset_val)}')\n",
    "print(f'number of batches: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KDpsns7pkxvC"
   },
   "source": [
    "# Tuning some hyperparameter and the model layer with some function like relu, sigmoid, tanh, ELUs and softmax.\n",
    "\n",
    "**From testing experience here and literature research, combination of sigmoid and adam seems best.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bWAppnsegYi8",
    "outputId": "e98df3ba-b58e-40c8-c31b-dc4b20f3fd4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_4 (LSTM)                (None, 32)                6400      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 17)                561       \n",
      "=================================================================\n",
      "Total params: 6,961\n",
      "Trainable params: 6,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    keras.layers.Input(shape=(inputs.shape[1], inputs.shape[2])),\n",
    "    keras.layers.LSTM(32, activation='sigmoid'),\n",
    "    keras.layers.Dense(len(target_names))\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=learning_rate), loss=\"mse\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1ngSu0egYi9",
    "outputId": "29df2b90-d7ea-458b-e612-f9f2cca1eaa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "Epoch 1/50\n",
      "20/20 [==============================] - 2s 46ms/step - loss: 0.2736 - val_loss: 0.3706\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.37057, saving model to covid_model_checkpoint.h5\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.1090 - val_loss: 0.2441\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.37057 to 0.24412, saving model to covid_model_checkpoint.h5\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0835 - val_loss: 0.2041\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.24412 to 0.20410, saving model to covid_model_checkpoint.h5\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.0848 - val_loss: 0.1931\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.20410 to 0.19311, saving model to covid_model_checkpoint.h5\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0842 - val_loss: 0.1899\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.19311 to 0.18994, saving model to covid_model_checkpoint.h5\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0813 - val_loss: 0.1886\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.18994 to 0.18861, saving model to covid_model_checkpoint.h5\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0773 - val_loss: 0.1877\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.18861 to 0.18773, saving model to covid_model_checkpoint.h5\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0732 - val_loss: 0.1867\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.18773 to 0.18669, saving model to covid_model_checkpoint.h5\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0692 - val_loss: 0.1854\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.18669 to 0.18544, saving model to covid_model_checkpoint.h5\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 0s 21ms/step - loss: 0.0654 - val_loss: 0.1841\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.18544 to 0.18408, saving model to covid_model_checkpoint.h5\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0616 - val_loss: 0.1827\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.18408 to 0.18268, saving model to covid_model_checkpoint.h5\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0578 - val_loss: 0.1812\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.18268 to 0.18123, saving model to covid_model_checkpoint.h5\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0540 - val_loss: 0.1798\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.18123 to 0.17976, saving model to covid_model_checkpoint.h5\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0503 - val_loss: 0.1783\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.17976 to 0.17826, saving model to covid_model_checkpoint.h5\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0466 - val_loss: 0.1768\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.17826 to 0.17675, saving model to covid_model_checkpoint.h5\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0432 - val_loss: 0.1752\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.17675 to 0.17524, saving model to covid_model_checkpoint.h5\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0398 - val_loss: 0.1737\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.17524 to 0.17375, saving model to covid_model_checkpoint.h5\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0367 - val_loss: 0.1723\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.17375 to 0.17225, saving model to covid_model_checkpoint.h5\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0338 - val_loss: 0.1708\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.17225 to 0.17076, saving model to covid_model_checkpoint.h5\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0311 - val_loss: 0.1693\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.17076 to 0.16926, saving model to covid_model_checkpoint.h5\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0287 - val_loss: 0.1677\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.16926 to 0.16772, saving model to covid_model_checkpoint.h5\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.0266 - val_loss: 0.1661\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.16772 to 0.16611, saving model to covid_model_checkpoint.h5\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0247 - val_loss: 0.1644\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.16611 to 0.16444, saving model to covid_model_checkpoint.h5\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.0231 - val_loss: 0.1627\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.16444 to 0.16268, saving model to covid_model_checkpoint.h5\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0218 - val_loss: 0.1608\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.16268 to 0.16084, saving model to covid_model_checkpoint.h5\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0207 - val_loss: 0.1589\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.16084 to 0.15892, saving model to covid_model_checkpoint.h5\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0198 - val_loss: 0.1569\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.15892 to 0.15695, saving model to covid_model_checkpoint.h5\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0190 - val_loss: 0.1549\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.15695 to 0.15493, saving model to covid_model_checkpoint.h5\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.0183 - val_loss: 0.1529\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.15493 to 0.15288, saving model to covid_model_checkpoint.h5\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0177 - val_loss: 0.1508\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.15288 to 0.15081, saving model to covid_model_checkpoint.h5\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0171 - val_loss: 0.1487\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.15081 to 0.14873, saving model to covid_model_checkpoint.h5\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0166 - val_loss: 0.1467\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.14873 to 0.14665, saving model to covid_model_checkpoint.h5\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0162 - val_loss: 0.1446\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.14665 to 0.14458, saving model to covid_model_checkpoint.h5\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0157 - val_loss: 0.1425\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.14458 to 0.14254, saving model to covid_model_checkpoint.h5\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0153 - val_loss: 0.1405\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.14254 to 0.14051, saving model to covid_model_checkpoint.h5\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0148 - val_loss: 0.1385\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.14051 to 0.13852, saving model to covid_model_checkpoint.h5\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.0144 - val_loss: 0.1366\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.13852 to 0.13656, saving model to covid_model_checkpoint.h5\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0140 - val_loss: 0.1346\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.13656 to 0.13463, saving model to covid_model_checkpoint.h5\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0136 - val_loss: 0.1327\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.13463 to 0.13274, saving model to covid_model_checkpoint.h5\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.0132 - val_loss: 0.1309\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.13274 to 0.13089, saving model to covid_model_checkpoint.h5\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0129 - val_loss: 0.1291\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.13089 to 0.12907, saving model to covid_model_checkpoint.h5\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0125 - val_loss: 0.1273\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.12907 to 0.12729, saving model to covid_model_checkpoint.h5\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0121 - val_loss: 0.1255\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.12729 to 0.12555, saving model to covid_model_checkpoint.h5\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 0s 16ms/step - loss: 0.0118 - val_loss: 0.1238\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.12555 to 0.12383, saving model to covid_model_checkpoint.h5\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0114 - val_loss: 0.1221\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.12383 to 0.12215, saving model to covid_model_checkpoint.h5\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0111 - val_loss: 0.1205\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.12215 to 0.12049, saving model to covid_model_checkpoint.h5\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 0s 18ms/step - loss: 0.0108 - val_loss: 0.1189\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.12049 to 0.11887, saving model to covid_model_checkpoint.h5\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 0s 20ms/step - loss: 0.0105 - val_loss: 0.1173\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.11887 to 0.11728, saving model to covid_model_checkpoint.h5\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 0s 19ms/step - loss: 0.0102 - val_loss: 0.1157\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.11728 to 0.11572, saving model to covid_model_checkpoint.h5\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 0s 17ms/step - loss: 0.0099 - val_loss: 0.1142\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.11572 to 0.11419, saving model to covid_model_checkpoint.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "path_checkpoint = \"covid_model_checkpoint.h5\"\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=5)\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    filepath=path_checkpoint,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "if os.path.exists('./logs'):\n",
    "    shutil.rmtree('./logs/')\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=epochs,\n",
    "    validation_data=dataset_val,\n",
    "    callbacks=[es_callback, modelckpt_callback, tensorboard_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JYct3d5oxFGM"
   },
   "source": [
    "## Visualization of the training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "54gLN5YkgYi-",
    "outputId": "91e44ff6-f300-4971-cb2b-9c89b761b241"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# defining a function to visualise the training and validation loss\n",
    "def visualising_loss(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(len(loss))\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'blue', label = 'Training loss')\n",
    "  plt.plot(epochs, val_loss, 'green', label = 'Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "visualising_loss(history, 'Training and Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eiD1PCBgYi-"
   },
   "outputs": [],
   "source": [
    "## We would need more time to carry out a Multi-stage series prediction"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Covid_Model_Ratawfiq11042021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
